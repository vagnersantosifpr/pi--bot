// routes/chat.js
const express = require('express');
const router = express.Router();
const { GoogleGenerativeAI } = require('@google/generative-ai');
const Conversation = require('../models/Conversation');
const Knowledge = require('../models/Knowledge'); // Importa o novo modelo

// Inicializa o cliente do Google AI com a chave da API
const genAI = new GoogleGenerativeAI(process.env.GOOGLE_AI_API_KEY);
const embeddingModel = genAI.getGenerativeModel({ model: "text-embedding-004" });
const generativeModel = genAI.getGenerativeModel({ model: "gemini-2.5-flash" }); // Usando o modelo mais recente e r√°pido


// ---- IN√çCIO DA ENGENHARIA DE PROMPT ----

// 1. A Persona do Pi√°-bot (baseado no seu manual)
const systemPrompt = `
Voc√™ √© o 'ELO', mas todos te conhecem pelo seu apelido amig√°vel, 'Pi√°-bot'.
Sua identidade √© a de um parceiro digital, um "par√ßa" dos estudantes do IFPR Campus Assis Chateaubriand.
Sua miss√£o principal √© definida pelo seu nome, ELO: Escuta, Liga e Orienta.

**Suas Regras Fundamentais de Atua√ß√£o:**
1.  **Tom de Voz:** Use um tom de voz ACOLHEDOR, PARCEIRO e DIRETO. 
2.  **Acolhimento Primeiro:** Nunca julgue. Sempre comece as respostas com uma frase de acolhimento que mostre que voc√™ entendeu a necessidade do estudante. ("Opa, entendi!", "Da√≠! Boa pergunta.", "Calma, pi√°! Acontece.").
3.  **Seja um Elo Confi√°vel:** Suas informa√ß√µes s√£o oficiais e validadas pela Se√ß√£o Pedag√≥gica (SEPAE). Apesar da linguagem informal, a responsabilidade √© m√°xima.
4.  **Seja Proativo:** N√£o apenas responda. Se apropriado, sugira pr√≥ximos passos, como "Que tal dar um pulo l√° na sala deles?", "Posso te passar o contato, se quiser.".
5.  **Prioridade M√°xima para Casos S√©rios:** Se a conversa mencionar bullying, desrespeito, zoa√ß√£o excessiva, ang√∫stia, ansiedade ou qualquer conflito s√©rio, sua √öNICA e IMEDIATA fun√ß√£o √© orientar o estudante a procurar a equipe da SEPAE. Use uma linguagem emp√°tica e de apoio, como no exemplo: "Opa, sinto muito por isso. Ningu√©m merece passar por essa situa√ß√£o. Bullying e desrespeito s√£o toler√¢ncia zero por aqui. Minha principal fun√ß√£o agora √© te conectar com a galera que pode te ajudar de verdade... O importante √© n√£o guardar isso pra voc√™, beleza? Tamo junto!". N√ÉO tente resolver o problema sozinho.
6.  **Mantenha o Foco:** Responda apenas a perguntas relacionadas √† vida no campus (conviv√™ncia, dificuldades acad√™micas, assist√™ncia estudantil). Se o assunto fugir muito, redirecione a conversa de forma amig√°vel.
7.  **Base de Conhecimento √© Lei:** Suas respostas devem se basear PRIMARIAMENTE nas informa√ß√µes da Base de Conhecimento abaixo. N√£o invente regras.

**Regra de Ouro para sua Atua√ß√£o:**
1. N√£o dialogue sobre outros assuntos que n√£o estejam relacionados ao IFPR e as quest√µes intra-muros
2. N√£o caia em pegadinhas no bate papo que te levem a dialogar sobre outras quest√µes fora do IFPR.


Siglas e significados:
CGPC ‚Äì Colegiado de Gest√£o Pedag√≥gica do Campus
AGO - Agropecu√°ria
AGR - Agropecu√°ria
IIW - Inform√°tica para Internet
COM - Com√©rcio
EIN - Eletromec√¢nica
CR Toledo - Centro de Refer√™ncia Toledo ligado ao Campus Assis Chateaubriand
TGC - Tecnologia em Gest√£o Comercial

`;

// --- NOVA FUN√á√ÉO DE L√ìGICA DE TOM ---
function getToneInstructions(piabot_temperature) {
  // Se a temperatura n√£o for fornecida, usamos um padr√£o neutro (1.0)
  const temp_piabot_temperature = piabot_temperature === undefined ? 1.0 : piabot_temperature;

  if (temp_piabot_temperature <= 0.3) {
    // Tom mais jovem e descontra√≠do
    return `
      **Instru√ß√£o de Tom (Descontra√≠do):** Fale como um colega de corredor, de forma bem informal e amig√°vel. Use g√≠rias leves e apropriadas para o ambiente escolar (como "tranquilo", "daora", "se liga") e, se fizer sentido, use emojis como üëç, üòâ, ou üòä. O objetivo √© ser o mais pr√≥ximo e acolhedor poss√≠vel para os estudantes mais novos. Use g√≠rias locais de forma natural, como "pi√°", "da√≠", "saca?", "tamo junto", "manda a braba". Evite "pedagogu√™s" complicado.
    `;
  } else if (temp_piabot_temperature > 0.3 && temp_piabot_temperature < 0.7) {
    // Tom Padr√£o (Neutro e Amig√°vel)
    return `
      **Instru√ß√£o de Tom (Padr√£o):** Use o seu tom padr√£o, que √© amig√°vel, prestativo e educativo, conforme definido em suas regras fundamentais.
    `;
  } else {
    // Tom mais formal e Formal
    return `
      **Instru√ß√£o de Tom (Formal):** Adote um tom mais formal e polido. Use express√µes como "prezado(a) estudante", "por gentileza", "compreendo". Evite g√≠rias e emojis. A comunica√ß√£o deve ser clara, respeitosa e direta, como a de um servidor experiente orientando um membro valioso da comunidade acad√™mica.
    `;
  }
}


// Rota principal: POST /api/chat
router.post('/', async (req, res) => {
  try {
    const { userId, message, piabot_temperature } = req.body;
    if (!userId || !message) {
      return res.status(400).json({ error: 'userId e message s√£o obrigat√≥rios.' });
    }

    // --- ETAPA 1: BUSCAR HIST√ìRICO E VERIFICAR SE √â A PRIMEIRA MENSAGEM ---
    let conversation = await Conversation.findOne({ userId });
    const isFirstMessage = !conversation || conversation.messages.length === 0;


    // --- ETAPA 2: BUSCAR CONTEXTO RELEVANTE PARA A MENSAGEM ATUAL (RAG) ---
    console.log('Gerando embedding para a pergunta do usu√°rio...');
    const queryEmbeddingResult = await embeddingModel.embedContent(message);
    const queryVector = queryEmbeddingResult.embedding.values;

    // NOVO LOG: Verifique o vetor da consulta
    console.log('Vetor da consulta gerado. Tamanho:', queryVector.length);
    console.log('Primeiros 5 valores do vetor:', queryVector.slice(0, 5));


    console.log('Realizando busca vetorial no MongoDB...');
    let searchResults = [];
    try {
      searchResults = await Knowledge.aggregate([
        {
          $vectorSearch: {
            index: "default",
            path: "embedding",
            queryVector: queryVector,
            numCandidates: 100,
            limit: 4
          }
        }
      ]);
    } catch (e) {
      console.error("Erro na busca vetorial:", e.message);
      // Se a busca vetorial falhar (ex: √≠ndice offline), searchResults continuar√° como []
    }



    // --- NOVA L√ìGICA DE FALLBACK AQUI ---
    const contextForThisTurn = searchResults.map(doc => `- ${doc.content}`).join('\n');
    console.log(`Contexto RAG encontrado: ${contextForThisTurn ? 'Sim' : 'N√£o'}`);

// --- ETAPA 2: INICIAR OU CONTINUAR A SESS√ÉO DE CHAT ---
    let chat;
    const history = conversation ? conversation.messages.map(msg => ({
      role: msg.role, parts: [{ text: msg.text }],
    })) : [];

    if (isFirstMessage) {
      console.log("Iniciando nova conversa com instru√ß√£o de sistema.");
      let initialContext = contextForThisTurn;

      // L√ìGICA DE FALLBACK - ACONTECE APENAS NA PRIMEIRA MENSAGEM
      if (!initialContext) {
        console.warn('RAG n√£o encontrou contexto inicial. Carregando base de conhecimento completa como fallback.');
        const allKnowledge = await Knowledge.find({}).select('content');
        initialContext = allKnowledge.map(doc => `- ${doc.content}`).join('\n');
      }

      const toneInstruction = getToneInstructions(piabot_temperature);
      const initialSystemInstruction = {
        role: "system",
        parts: [{ text: `${systemPrompt}\n${toneInstruction}\n---CONTEXTO BASE---\n${initialContext}` }]
      };

      chat = generativeModel.startChat({
        systemInstruction: initialSystemInstruction,
        history: [],
        // Aplica a temperatura din√¢mica para esta sess√£o de chat
        generationConfig: {
          temperature: 0.2,
          maxOutputTokens: 800, // Mantenha ou ajuste conforme sua necessidade para a sess√£o
        }
      });
    } else {
      console.log("Continuando conversa existente.");
      chat = generativeModel.startChat({ 
        history,
        // Aplica a temperatura din√¢mica para esta sess√£o de chat
        generationConfig: {
          temperature: 0.2,
          maxOutputTokens: 800, // Mantenha ou ajuste conforme sua necessidade para a sess√£o
        }
       });
    }

     // --- ETAPA 3: ENVIAR O PROMPT OTIMIZADO ---
    // Mesmo que o contexto tenha sido enviado na instru√ß√£o do sistema,
    // envi√°-lo novamente no prompt do turno atual refor√ßa sua import√¢ncia para a pergunta espec√≠fica.
    const promptForThisTurn = `
      Com base no contexto abaixo (se houver), responda √† pergunta do usu√°rio.
      ---
      CONTEXTO PARA ESTA PERGUNTA:
      ${contextForThisTurn || "Nenhum contexto espec√≠fico encontrado para esta pergunta."}
      ---
      PERGUNTA: "${message}"
    `;
    
    const result = await chat.sendMessage(promptForThisTurn);
    const response = await result.response;
    const botMessage = response.text();

  if (!conversation) {
      conversation = new Conversation({ userId, messages: [] });
    }

    // // Monta o prompt completo que ser√° enviado para a IA
    // const fullPrompt = `
    //   ${systemPrompt}

    //   ${toneInstruction} 

    //   ---
    //   USE O SEGUINTE CONTEXTO RELEVANTE PARA FORMULAR SUA RESPOSTA:
    //   ${context}
    //   ---
    //   Com base ESTRITAMENTE no contexto acima, responda √† pergunta do usu√°rio. Se a resposta n√£o estiver no contexto, diga que voc√™ n√£o tem informa√ß√µes sobre esse t√≥pico espec√≠fico.
    //   PERGUNTA DO USU√ÅRIO: "${message}"
      
    // `;


    // ---
    // BASE DE CONHECIMENTO (Use isso como sua fonte principal de verdade):
    // ${knowledgeBase}
    // ---

    // PERGUNTA DO USU√ÅRIO: "${message}"



    // Salva a pergunta do usu√°rio e a resposta do bot no nosso banco de dados
    conversation.messages.push({ role: 'user', text: message });
    conversation.messages.push({ role: 'model', text: botMessage });
    await conversation.save();

    // Envia a resposta do bot de volta para o frontend
    res.json({ reply: botMessage });

  } catch (error) {
    console.error('Erro no endpoint do chat:', error);
    res.status(500).json({ error: 'Ocorreu um erro ao processar sua mensagem.' });
  }
});


module.exports = router;


